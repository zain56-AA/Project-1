# Project-1
# Data Science Internship – Final Submission

 # Data Science Internship – Final Submission

## Overview

This repository contains the solutions for all four tasks assigned as part of the **Data Science Internship** program. Each task covers a core area of data science, including data analysis, machine learning, and natural language processing.

---

## Task 1: EDA and Visualization of a Real-World Dataset

### Objective:
Perform Exploratory Data Analysis (EDA) on a real-world dataset (e.g., Titanic or Airbnb Listings).

### Steps Followed:
- Loaded dataset using Pandas
- Cleaned data (handled missing values, removed duplicates, treated outliers)
- Created visualizations:
  - Bar charts for categorical features
  - Histograms for numeric features
  - Correlation heatmap
- Summarized key insights from the data

### Output:
A Jupyter Notebook with visualizations and written observations.

---

## Task 2: Text Sentiment Analysis

### Objective:
Build a sentiment analysis model using the IMDB Reviews dataset.

### Steps Followed:
- Preprocessed text (tokenization, stopword removal, lemmatization)
- Converted text to numerical form using TF-IDF
- Trained a Logistic Regression model for classification
- Evaluated model with precision, recall, and F1-score

### Output:
A Python script that processes text, predicts sentiment, and prints evaluation metrics.

---

## Task 3: Fraud Detection System

### Objective:
Build a system to detect fraudulent transactions using the Credit Card Fraud dataset.

### Steps Followed:
- Handled data imbalance using SMOTE/undersampling
- Trained a Random Forest classifier
- Evaluated performance using precision, recall, and F1-score
- Built a command-line interface to test the model with new input

### Output:
A Python script with model training, evaluation, and an interactive interface.

---

## Task 4: Predicting House Prices Using Boston Housing Dataset

### Objective:
Build regression models **from scratch** to predict house prices.

### Steps Followed:
- Normalized numerical features
- Implemented:
  - Linear Regression (fully from scratch)
  - Random Forest (simplified)
  - XGBoost (simplified boosting logic)
- Compared model performance using RMSE and R²
- Visualized feature importance (for tree-based models)

### Output:
A complete script showing model logic, training results, and plots.

---

